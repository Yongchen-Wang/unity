# 混合现实机器人控制系统 - 功能说明与使用指南

## 📋 系统概述

这是一个**混合现实（Mixed Reality）机器人控制系统**，主要功能是：
- 通过 **HoloLens/Mixed Reality 设备**的手部追踪来控制 **Sensapex 机器人**
- 使用**相机图像处理**进行视觉反馈和位置检测
- 在 **Unity** 中可视化机器人位置和场景

## 🏗️ 系统架构

```
┌─────────────────┐         TCP/UDP          ┌──────────────────┐
│   Unity/MR设备   │ ──────────────────────> │   Python控制端    │
│  (手部追踪数据)   │                         │  (机器人控制)     │
└─────────────────┘ <──────────────────────  └──────────────────┘
         ▲                    TCP                      │
         │                                            │
         │                                            ▼
         │                                    ┌──────────────┐
         │                                    │ Sensapex机器人│
         │                                    └──────────────┘
         │
         └──────────────────────────────────────────┘
                    (位置反馈)
```

## 📁 文件结构说明

### Unity 文件夹（Unity项目）
- **TCPSend.cs**: 发送手部追踪数据到Python（左手控制）
- **TCPReceiver.cs**: 接收机器人位置数据
- **HandTrackingHandler.cs**: 手部追踪处理（UDP版本，右手控制）
- **MoveX_RealRobot.cs / MoveY_RealRobot.cs / MoveZ_RealRobot.cs**: 根据机器人位置更新Unity中的物体位置
- **BallPositionReceiver.cs**: 接收球的位置数据（用于相机检测）
- **VideoDisplay.cs**: 显示视频流
- 各种 `.fbx` 和 `.mat` 文件：3D模型和材质资源

### Sensapex 文件夹（Python控制端）

#### 机器人控制脚本
- **manual_control_one_robot.py**: 单机器人控制（双向通信）
  - 监听端口：12345（接收Unity手部数据）
  - 发送端口：5005（发送机器人位置到Unity）
  
- **manual-control_two_robots.py**: 双机器人控制
  - 左手：监听12345，发送到5005
  - 右手：监听22345，发送到5225

- **TCP_Receiver_1.py**: 单机器人接收控制（仅接收，不反馈）
- **TCP_sender_1.py**: 仅发送机器人位置（测试用）

#### 相机图像处理
- **camera_image_processing/camera_final.py**: 
  - WebSocket服务器，端口8765（视频流）和8766（球位置）
  - 使用HSV颜色空间检测球的位置
  - 像素坐标转换为空间坐标

- **camera_image_processing/PC2Unity.py**: TCP方式发送视频流

## 🔌 通信协议

### 端口配置

| 功能 | 端口 | 方向 | 协议 |
|------|------|------|------|
| Unity → Python（左手） | 12345 | Unity发送 | TCP |
| Unity → Python（右手） | 22345 | Unity发送 | TCP |
| Python → Unity（位置反馈） | 5005 | Python发送 | TCP |
| Python → Unity（右手位置） | 5225 | Python发送 | TCP |
| 视频流（WebSocket） | 8765 | Python发送 | WebSocket |
| 球位置（WebSocket） | 8766 | Python发送 | WebSocket |

### 数据格式

**手部追踪数据**（Unity → Python）:
```
"x,y,z"  // 例如: "0.001,0.002,-0.001"
```

**机器人位置数据**（Python → Unity）:
```
"x,y,z"  // 例如: "10000,10000,10000"
```

## 🚀 使用步骤

### 前置准备：Unity项目设置

**重要**：Unity项目需要先正确设置才能使用！

1. **使用Unity Hub打开项目**：
   - 打开Unity Hub
   - 点击"添加"或"Open"
   - 选择 `Unity` 文件夹
   - Unity会自动检测并提示安装对应版本（2020.3.48f1或更高）

2. **等待包安装**：
   - Unity会自动从 `Packages/manifest.json` 安装MRTK等依赖包
   - 首次打开可能需要几分钟来导入资源

3. **配置MRTK**（如果使用HoloLens）：
   - 菜单栏选择 `Mixed Reality > Toolkit > Add to Scene and Configure...`
   - 选择适合你设备的配置文件

4. **检查场景设置**：
   - 打开 `Assets/SampleScene.unity`
   - 确保场景中有必要的脚本组件（TCPSend, TCPReceiver等）

详细说明请查看 `Unity/README.md`

### 方案一：单机器人控制

#### 1. 启动Python控制端
```bash
cd Sensapex
python manual_control_one_robot.py
```

**配置说明**：
- 确保Sensapex机器人已连接（设备ID=1）
- 检查IP地址配置：
  - `target_ip`：Unity所在机器的IP（默认192.168.137.137或127.0.0.1）
  - `server_port`：12345（接收Unity数据）

#### 2. 启动Unity场景
- 打开Unity项目
- 加载 `SampleScene.unity`
- 确保场景中有以下组件：
  - `TCPSend` 脚本（发送手部追踪数据）
  - `TCPReceiver` 脚本（接收机器人位置）
  - `MoveX_RealRobot` / `MoveY_RealRobot` / `MoveZ_RealRobot`（更新可视化位置）

#### 3. 运行Unity场景
- 在Mixed Reality设备上运行或使用Unity编辑器
- 移动左手食指，机器人会跟随移动

### 方案二：双机器人控制

#### 1. 启动Python控制端
```bash
cd Sensapex
python manual-control_two_robots.py
```

**配置说明**：
- 需要两个Sensapex机器人（设备ID=1和2）
- 左手控制机器人1，右手控制机器人2

#### 2. Unity配置
- 需要两个 `TCPSend` 实例：
  - 一个连接到12345（左手）
  - 一个连接到22345（右手）

### 方案三：相机图像处理

#### 1. 启动相机服务器
```bash
cd Sensapex/camera_image_processing
python camera_final.py
```

#### 2. Unity中接收
- 使用WebSocket客户端连接 `localhost:8765`（视频）
- 使用WebSocket客户端连接 `localhost:8766`（球位置）
- `BallPositionReceiver.cs` 会自动更新球的位置

## ⚙️ 配置要点

### IP地址配置

**Python端** (`manual_control_one_robot.py`):
```python
target_ip = '192.168.137.137'  # Unity所在机器的IP
# 或使用本地回环
target_ip = '127.0.0.1'  # 本地测试
```

**Unity端** (`TCPSend.cs`):
```csharp
private string targetIP = "127.0.0.1";  // Python所在机器的IP
private int targetPort = 12345;
```

### 坐标转换参数

**Python端**（手部移动转换为机器人移动）:
```python
temp_previousx = previousx + 64000 * deltax  # X轴缩放因子
temp_previousz = previousz - 64000 * deltaz  # Z轴缩放因子
temp_previousy = previousy - 96000 * deltay  # Y轴缩放因子
```

**Unity端**（机器人位置转换为Unity坐标）:
```csharp
float newX = (TCPReceiver.latestPosition.x - positionOffset) / scale;
// positionOffset = 10000, scale = 400000
```

### 安全限制

机器人移动范围限制：
```python
max_limit = 18000  # 最大位置
min_limit = 2000   # 最小位置
```

## 🔧 依赖项

### Python依赖
```bash
pip install sensapex
pip install opencv-python
pip install websockets
pip install numpy
```

### Unity依赖
- Mixed Reality Toolkit (MRTK)
- Unity 2020.3 或更高版本
- websocket-sharp.dll（已在项目中）

## 📝 注意事项

1. **网络连接**：确保Unity和Python在同一网络，或使用正确的IP地址
2. **端口占用**：确保所需端口未被其他程序占用
3. **机器人初始化**：首次使用可能需要校准机器人零位
4. **坐标系统**：注意Unity和机器人坐标系统的差异（可能需要调整轴映射）
5. **延迟控制**：更新间隔设置为0.1秒，可根据需要调整

## 🐛 故障排除

### 连接失败
- 检查防火墙设置
- 确认IP地址和端口正确
- 检查网络连接

### 机器人不移动
- 检查Sensapex设备连接
- 确认设备ID正确（1或2）
- 检查坐标是否在限制范围内

### 手部追踪不工作
- 确认MRTK已正确配置
- 检查手部追踪权限
- 确认使用的是正确的handedness（Left/Right）

## 📚 相关文件说明

- `reset.py`: 机器人复位脚本
- `test_2robots_kalman.py`: 双机器人卡尔曼滤波测试
- `camera_image_processing/`: 各种图像处理测试脚本

